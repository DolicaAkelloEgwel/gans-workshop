{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs with Python\n",
    "\n",
    "## Setup\n",
    "\n",
    "### 1. Go to this link: bit.ly/45svhk0\n",
    "### 2. Log in to your Google Drive account\n",
    "### 3. Make sure your files are in the right place"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Like in the previous workshop, we're going to import some libraries for the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggJNE19puADT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from urllib import request  # This is for downloading\n",
    "import zipfile  # This is for handling zip files\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick intro to booleans\n",
    "\n",
    "### Data type recap\n",
    "\n",
    "Earlier we discussed different types of variables you see in your code. The main examples we went through were strings (text data), integers (whole-numbers), and floats (numbers with a decimal place).\n",
    "\n",
    "A quick recap:\n",
    "```python\n",
    "my_string = \"some text!\"\n",
    "my_float = 39.59382\n",
    "my_int = 20\n",
    "```\n",
    "### Bools and why we're using them\n",
    "\n",
    "There is another basic data type that we frequently use in Python called booleans (or bools). These can either have the values `True` or `False`. They are used when we want a part of our code to run only when a certain condition has been met.\n",
    "\n",
    "The code we are using can take several hours to complete (depending on how many images you give and some other factors), so it's been written in such a way that it is possible to save the progress that the code has made so that it can pick up from where it left off later. THis is also useful if the code crashes for whatever reason, as the progress it has made will be preserved.\n",
    "\n",
    "However, this has the downside of creating progress files in your Google Drive folder that can build up in size quite quickly!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bools for our GAN\n",
    "\n",
    "Before running the code, we will set values for the following bools:\n",
    "- `do_preprocess` - Determines if we run or skip the code for resizing our image files. This will need to be done at least once.\n",
    "- `from_checkpoint` - Determines if the GAN starts from scratch, or picks up where it left off by loading a model file. For the first run this will have to be set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_preprocess = True\n",
    "from_checkpoint = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a basic example of what bools allow you to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bool = True\n",
    "\n",
    "if my_bool:\n",
    "    print(\"We will see this printed.\")\n",
    "\n",
    "if my_bool:\n",
    "    print(\"This will also be printed\")\n",
    "else:\n",
    "    print(\"But not this.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code contains an `if` statement. This is another keyword in Python used for conditional execution, basically meaning it helps us write code that is only run some of the time. Here we have used it to ensure that some text is printed only when `my_bool` is True.\n",
    "\n",
    "Now let's see what happens when something is false.\n",
    "\n",
    "**Exercise**: What will the output be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bool = False\n",
    "\n",
    "if my_bool:\n",
    "    print(\"This will be printed. Or will it...?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may remember that the first workshop showed us how to use `type()` to find the type of some data. Now we can use it with a bool to see that it is in fact a bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(True), type(False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Some Data\n",
    "\n",
    "Now that we understand a bit about what booleans do, please set the bool below to True or False depending on whether you've uploaded 500+ image files to Google Drive and have put them in the right folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHf6TJ9t_f-c",
    "outputId": "960210a4-56fa-4922-ddb1-d417b2caf279"
   },
   "outputs": [],
   "source": [
    "student_uploaded_own_data = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the GPU\n",
    "\n",
    "The Tensorflow library allows us to perform calculations with a GPU or CPU. Setting a GPU up on a desktop machine can be tricky, and sometimes a library won't recognise your GPU as being on your system, even when one is present. For this reason Tensorflow and other Python libraries that utilise the GPU often have a command for checking that a GPU has been detected on the system. This lets you know if you can continue coding, or if you need to do some troubleshooting and figure out why things didn't install properly.\n",
    "\n",
    "Fortunately we don't need to worry about these things when using Colab. The GPU is already setup for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGm8QAAeqPNi",
    "outputId": "53e7a301-72d9-415d-8477-d4c16b891783"
   },
   "outputs": [],
   "source": [
    "# check CUDA availability and set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Use GPU: {}\".format(str(device) != \"cpu\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Colab is somtimes able to tell that a Python Notebook requies the GPU, so you should have automatically been given a T4 runtime. You can check this in the top right."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Folder Names (and Data?)\n",
    "\n",
    "This code will create quite a bit of output, and so we'll need to create some folders to save all these files:\n",
    "\n",
    "- One folder for the resized images that we will feed into the GAN\n",
    "- Another folder for the model files that act as snapshots of how far the GAN has come along\n",
    "- And another for the computer-generated images\n",
    "\n",
    "Like in the previous workshop, the `os` library will be used for creating our paths. This for safety, as `os` knows what to do regardless of if you are running Windows, Linux, or Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"./drive/MyDrive/\"\n",
    "GANS_WORKSHOP_FOLDER = \"gans-workshop-files\"\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    project_dir = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit about `try-except`\n",
    "\n",
    "The purpose of `try-except` is to give the code a kind of Plan B on what to do when a certain block of code creates an error. Sometimes we are _expecting_ an error in a particular situation, and know what we want the code to do should this happen. This is where a `try-except` block comes into play. It allows us to say \"If you run across this problem as the code runs, do this instead.\"\n",
    "\n",
    "Here I am mounting the Google Drive folder in a `try-except` block because sometimes I run this code on a desktop. In this scenario the `from google.colab import drive` would lead to a `ModuleNotFoundError`. This is an error you get when you try to import a library that hasn't been installed on your system. When I am running this code on a desktop machine I am not importing Colab and instead getting the input files from my hard drive, and so I tell the code to use `os.getcwd()` as the path to work from. This is the _current working directory_.\n",
    "\n",
    "Here's an example below of _catching_ an error caused by using the wrong index for a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list contains three items\n",
    "my_list = [1, 2, 3]\n",
    "\n",
    "# This is how we print the items in a list line by line\n",
    "print(my_list[0])\n",
    "print(my_list[1])\n",
    "print(my_list[2])\n",
    "\n",
    "try:\n",
    "    # I am going to try and print the 4th item in the list\n",
    "    print(my_list[3])\n",
    "    print(\"Will the code reach this point?\")\n",
    "except IndexError:\n",
    "    print(\"You have accessed something outside of the list.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Files\n",
    "\n",
    "Now with that out of the way we can start sorting out the images to give to the GAN. Pick a type of image you want to download if you didn't already prepare some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Choose the type of data you wish to download if you don't already have something { display-mode: \"form\" }\n",
    "\n",
    "data_folder_name = \"cats\"  # @param [\"cats\", \"flowers\", \"abstract-paintings\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a conditional statement will download some data if it's needed, otherwise we'll go with the data you already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANS_WORKSHOP_FOLDER = \"gans-workshop-files\"\n",
    "\n",
    "if student_uploaded_own_data:\n",
    "    # Change this to the name of your data folder\n",
    "    data_folder_name = \"pokemon\"\n",
    "else:\n",
    "    data_path = os.path.join(project_dir, GANS_WORKSHOP_FOLDER, data_folder_name)\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path, exist_ok=True)\n",
    "        print(f\"Downloading {data_folder_name} dataset...\")\n",
    "        local_filename, _ = request.urlretrieve(\n",
    "            f\"https://github.com/DolicaAkelloEgwel/gans-datasets/raw/master/{data_folder_name}.zip\"\n",
    "        )\n",
    "        with zipfile.ZipFile(local_filename, \"r\") as downloaded_dataset:\n",
    "            downloaded_dataset.extractall(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to need quite a few folders for all the files that will be created from the code. These will be\n",
    "- A folder for our resized data\n",
    "- A folder for our model/checkpoint files\n",
    "- A folder for the GANs output images\n",
    "\n",
    "For the time being, we're just going to set the paths for these folders. That's because these folders may already exist, so there will need to be some conditional logic used to check if these folders even need to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_dir = os.path.join(project_dir, GANS_WORKSHOP_FOLDER)\n",
    "data_dir = os.path.join(workshop_dir, data_folder_name)\n",
    "data_resized_dir = os.path.join(workshop_dir, f\"{data_folder_name}-resized\")\n",
    "models_folder = os.path.join(workshop_dir, f\"{data_folder_name}-models\")\n",
    "image_folder = os.path.join(workshop_dir, f\"{data_folder_name}-gans-images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Files\n",
    "\n",
    "This code is designed to work with 128x128 images, so we're going to resize the images and place them in a new folder. Again, `os.mkdir` is used for this.\n",
    "\n",
    "With the folder for our preprocessed files created, we can now resize the images and save them there. In order to do this we loop through all the images in our data directory using `os.listdir`. This is something that will list all the files it can find in a folder, which is why I am using `image_filename` as the placeholder.\n",
    "\n",
    "Our `image_filename` is then sent to the `cv2.imread` command which will load the file into an array, and then sent again to the `cv2.resize` command so that it may be resized. Finally the resized images are saved to our `data_resized_dir` using the `cv2.imwrite` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_in_centre(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Crops an image in the centre to make it square.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image data to reshape.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The cropped image.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    # Only do the cropping if the image isn't square\n",
    "    if height != width:\n",
    "        min_side = min(height, width)\n",
    "        top, bot = (height - min_side) // 2, height - (height - min_side) // 2\n",
    "        left, right = (width - min_side) // 2, width - (width - min_side) // 2\n",
    "        image = image[top:bot, left:right, :]\n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mIQnG0tqP8y"
   },
   "outputs": [],
   "source": [
    "if do_preprocess:\n",
    "    # Make a folder for the resized images if one doesn't already exist\n",
    "    if not os.path.isdir(data_resized_dir):\n",
    "        os.mkdir(data_resized_dir)\n",
    "\n",
    "    # Go through each of our input images, resize them, and then save them to the new folder\n",
    "    for image_filename in os.listdir(data_dir):\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(data_dir, image_filename))\n",
    "            image = crop_image_in_centre(image)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            cv2.imwrite(os.path.join(data_resized_dir, image_filename), image)\n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes stray files such as `.DS_Store` make their way into our folders. Our `os.listdir` loop is simply going to find all the files in a folder and isn't smart enough to know that not all of these files will be images. This is why we use a `try-except` again to allow the code to keep going even when `cv2.imread` fails. This is fine, because if it fails to read a file as an image then the file most likely wasn't an actual image, so we can just ignore it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Helper Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a function that will plot several images in a grid. We'll use this to monitor the progress of the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path, mode):\n",
    "    \"\"\"Loads a numpy image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path for the image to load.\n",
    "        mode (str): The mode to give when converting the image.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The image in the form of a numpy array.\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(image_path).convert(mode))\n",
    "\n",
    "\n",
    "def get_batch(image_files, mode):\n",
    "    \"\"\"Creates a batch of images.\n",
    "\n",
    "    Args:\n",
    "        image_files (list): A list of several image files.\n",
    "        mode (str): The most to use when converting the images.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of a batch of images.\n",
    "    \"\"\"\n",
    "    data_batch = np.array(\n",
    "        [get_image(sample_file, mode) for sample_file in image_files]\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    # Make sure the images are in 4 dimensions\n",
    "    if len(data_batch.shape) < 4:\n",
    "        data_batch = data_batch.reshape(data_batch.shape + (1,))\n",
    "\n",
    "    return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpNvZp97rZwB"
   },
   "outputs": [],
   "source": [
    "def images_square_grid(images: np.ndarray, mode: str) -> Image:\n",
    "    \"\"\"Plots three images in a grid.\n",
    "\n",
    "    Args:\n",
    "        images (np.ndarray): A batch of 9 images.\n",
    "        mode (str): The mode argument given to Image.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: An Image object containing the 9 pictures.\n",
    "    \"\"\"\n",
    "    # Get maximum size for square grid of images\n",
    "    save_size = math.floor(np.sqrt(images.shape[0]))\n",
    "\n",
    "    # Scale to 0-255\n",
    "    images = (((images - images.min()) * 255) / (images.max() - images.min())).astype(\n",
    "        np.uint8\n",
    "    )\n",
    "\n",
    "    # Put images in a square arrangement\n",
    "    images_in_square = np.reshape(\n",
    "        images[: save_size * save_size],\n",
    "        (save_size, save_size, images.shape[1], images.shape[2], images.shape[3]),\n",
    "    )\n",
    "    if mode == \"L\":\n",
    "        images_in_square = np.squeeze(images_in_square, 4)\n",
    "\n",
    "    # Combine images to grid image\n",
    "    new_im = Image.new(mode, (images.shape[1] * save_size, images.shape[2] * save_size))\n",
    "    for col_i, col_images in enumerate(images_in_square):\n",
    "        for image_i, image in enumerate(col_images):\n",
    "            im = Image.fromarray(image, mode)\n",
    "            new_im.paste(im, (col_i * images.shape[1], image_i * images.shape[2]))\n",
    "\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_image(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Pre-process image.\"\"\"\n",
    "    # normalize\n",
    "    img = img / 128.0  # between 0 and 2\n",
    "    img -= 1.0  # between -1 and 1\n",
    "    # transpose\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a `Dataset` object for PyTorch to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"Dataset object for 64x64 pixel catface images.\"\"\"\n",
    "\n",
    "    def __init__(self, img_paths, mirror=True):\n",
    "        self.img_paths = img_paths\n",
    "        self.size = 128\n",
    "        self.mirror = mirror\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # mirror img with a 50% chance\n",
    "        if self.mirror:\n",
    "            if random.random() > 0.5:\n",
    "                img = img[:, ::-1, :]\n",
    "        # resize\n",
    "        img = cv2.resize(img, (self.size, self.size))\n",
    "\n",
    "        # normalize\n",
    "        img = _preprocess_image(img)\n",
    "\n",
    "        return torch.tensor(img.astype(np.float32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below will display 9 of our resized images by using the `images_square_grid` function that was defined earlier. This lets us know that the preprocessing worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "pUkW_Ylyrkke",
    "outputId": "0e6a79de-3f40-406a-8861-12b0400b5520"
   },
   "outputs": [],
   "source": [
    "# Create a list of the files in our resized images folder\n",
    "resized_data_filenames = [\n",
    "    os.path.join(data_resized_dir, resized_image_filename)\n",
    "    for resized_image_filename in os.listdir(data_resized_dir)\n",
    "]\n",
    "show_n_images = 9\n",
    "# Get a batch of 9 of the resized images\n",
    "train_images = get_batch(resized_data_filenames[:show_n_images], \"RGB\")\n",
    "# Create a grid from the resized images and then plot them\n",
    "plt.imshow(images_square_grid(train_images, \"RGB\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_img(img):\n",
    "    \"\"\"Transform a network output into displayable img.\"\"\"\n",
    "    img = img.transpose((1, 2, 0))\n",
    "    img += 1.0\n",
    "    img = (img * 128.0).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_grid(img_batch, grid_size, epoch, img_path):\n",
    "    \"\"\"Create a grid-like visualization from a batch of images and save it.\"\"\"\n",
    "    if grid_size**2 != img_batch.shape[0]:\n",
    "        print(\n",
    "            \"grid_size**2 and batch size not equal: {} {}. Skipping\".format(\n",
    "                grid_size**2, img_batch.shape[0]\n",
    "            )\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # create black canvas\n",
    "    img_size = img_batch.shape[2]\n",
    "    canvas = np.zeros(\n",
    "        (grid_size * (img_size + 2) - 2 + 28, grid_size * (img_size + 2) - 2, 3),\n",
    "        dtype=np.uint8,\n",
    "    )\n",
    "\n",
    "    # add the epoch number to the bottom\n",
    "    text_size = cv2.getTextSize(\n",
    "        \"Epoch {}\".format(epoch), cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1\n",
    "    )  # get text size\n",
    "    # calculate text position\n",
    "    text_left = (canvas.shape[1] - text_size[0][0]) // 2\n",
    "    text_bottom = canvas.shape[0] - (28 - text_size[0][1]) // 2\n",
    "    # add text\n",
    "    cv2.putText(\n",
    "        canvas,\n",
    "        \"Epoch {}\".format(epoch),\n",
    "        (text_left, text_bottom),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.6,\n",
    "        (255, 255, 255),\n",
    "        1,\n",
    "    )\n",
    "\n",
    "    for img_idx, img in enumerate(img_batch):\n",
    "        col = math.floor(img_idx / grid_size)\n",
    "        row = img_idx - col * grid_size\n",
    "        canvas[\n",
    "            col * (img_size + 2) : col * (img_size + 2) + img_size,\n",
    "            row * (img_size + 2) : row * (img_size + 2) + img_size,\n",
    "            :,\n",
    "        ] = postprocess_img(img)\n",
    "\n",
    "    cv2.imwrite(img_path, canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"Initialize the weights of a module randomly, using Gaussian distribution.\"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1 or classname.find(\"ConvTranspose2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_name,\n",
    "        in_size,\n",
    "        out_size,\n",
    "        normalize=True,\n",
    "        kernel_size=4,\n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        bias=False,\n",
    "        activation_fn=nn.LeakyReLU(0.2),\n",
    "    ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module(\n",
    "            block_name + \"_conv2d\",\n",
    "            nn.Conv2d(\n",
    "                in_size,\n",
    "                out_size,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=bias,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if normalize:\n",
    "            self.model.add_module(block_name + \"_norm\", nn.BatchNorm2d(out_size))\n",
    "\n",
    "        if activation_fn is not None:\n",
    "            self.model.add_module(block_name + \"_activation_fn\", activation_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Generator\n",
    "\n",
    "Tensowflow allows us to group variables together in a `variable_scope`. This means that the variables belonging to the generator will all have `generator` in the name, and likewise, the variables belonging to the discriminator will have `discriminator` in the name.\n",
    "\n",
    "This approach also means that the netowrks can be reused with different inputs.\n",
    "- Generator: The generator will be trained, but we're also going to be sampling from it (retrieving our fake data) during the training.\n",
    "- Discriminator: The discriminator will need to share images between the fake and real input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_name,\n",
    "        in_size,\n",
    "        out_size,\n",
    "        normalize=True,\n",
    "        kernel_size=4,\n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        bias=False,\n",
    "        activation_fn=nn.ReLU(),\n",
    "    ):\n",
    "        super(TransConvBlock, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module(\n",
    "            block_name + \"_trans_conv\",\n",
    "            nn.ConvTranspose2d(\n",
    "                in_size,\n",
    "                out_size,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=bias,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if normalize:\n",
    "            self.model.add_module(block_name + \"_norm\", nn.BatchNorm2d(out_size))\n",
    "\n",
    "        if activation_fn is not None:\n",
    "            self.model.add_module(block_name + \"_activation_fn\", activation_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OrZ8idXDYfy"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.upconv1 = TransConvBlock(\n",
    "            \"gen_start_block\",\n",
    "            100,\n",
    "            1024,\n",
    "            normalize=True,\n",
    "            kernel_size=4,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "        )\n",
    "        self.upconv2 = TransConvBlock(\n",
    "            \"gen_mid_block1\",\n",
    "            1024,\n",
    "            512,\n",
    "            normalize=True,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.upconv3 = TransConvBlock(\n",
    "            \"gen_mid_block2\",\n",
    "            512,\n",
    "            256,\n",
    "            normalize=True,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.upconv4 = TransConvBlock(\n",
    "            \"gen_mid_block3\",\n",
    "            256,\n",
    "            128,\n",
    "            normalize=True,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.upconv5 = TransConvBlock(\n",
    "            \"gen_end_block\",\n",
    "            128,\n",
    "            3,\n",
    "            normalize=False,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            activation_fn=nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upconv1(x)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.upconv4(x)\n",
    "        x = self.upconv5(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfguoTo4DdEr"
   },
   "outputs": [],
   "source": [
    "class DCGANDiscriminator(nn.Module):\n",
    "    \"\"\"DCGAN Discriminator architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(\n",
    "            \"disc_start_block\",\n",
    "            3,\n",
    "            128,\n",
    "            normalize=False,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.conv2 = ConvBlock(\n",
    "            \"disc_mid_block1\",\n",
    "            128,\n",
    "            256,\n",
    "            normalize=True,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.conv3 = ConvBlock(\n",
    "            \"disc_mid_block2\",\n",
    "            256,\n",
    "            512,\n",
    "            normalize=True,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.conv4 = ConvBlock(\n",
    "            \"disc_mid_block3\",\n",
    "            512,\n",
    "            1024,\n",
    "            normalize=True,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.conv5 = ConvBlock(\n",
    "            \"disc_end_block\",\n",
    "            1024,\n",
    "            1,\n",
    "            normalize=False,\n",
    "            kernel_size=4,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            activation_fn=nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(resized_data_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_training(train_config):\n",
    "    \"\"\"Initialize networks, optimizers and the data pipeline.\"\"\"\n",
    "    # create dataset\n",
    "    dataset = Dataset(train_config[\"data_path\"])\n",
    "    print(\"num of images:\", len(dataset))\n",
    "\n",
    "    # define data loader\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=train_config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=train_config[\"num_workers\"],\n",
    "    )\n",
    "\n",
    "    # init networks\n",
    "    generator = Generator()  # the generator is the same for both the DCGAN and the WGAN\n",
    "    generator.apply(weights_init)\n",
    "    generator = generator.to(device)\n",
    "\n",
    "    discriminator = DCGANDiscriminator()\n",
    "    discriminator.apply(weights_init)\n",
    "    discriminator = discriminator.to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizers = {\n",
    "        \"gen\": torch.optim.Adam(\n",
    "            generator.parameters(),\n",
    "            lr=train_config[\"learning_rate_g\"],\n",
    "            betas=(train_config[\"b1\"], train_config[\"b2\"]),\n",
    "        ),\n",
    "        \"disc\": torch.optim.Adam(\n",
    "            discriminator.parameters(),\n",
    "            lr=train_config[\"learning_rate_d\"],\n",
    "            betas=(train_config[\"b1\"], train_config[\"b2\"]),\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # make save dir, if needed\n",
    "    os.makedirs(os.path.join(train_config[\"checkpoint_path\"], \"weights\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(train_config[\"checkpoint_path\"], \"samples\"), exist_ok=True)\n",
    "\n",
    "    # load weights if the training is not starting from the beginning\n",
    "    if train_config[\"start_epoch\"] > 1:\n",
    "        gen_path = os.path.join(\n",
    "            train_config[\"checkpoint_path\"],\n",
    "            \"weights\",\n",
    "            \"checkpoint_ep{}_gen.pt\".format(train_config[\"start_epoch\"] - 1),\n",
    "        )\n",
    "        disc_path = os.path.join(\n",
    "            train_config[\"checkpoint_path\"],\n",
    "            \"weights\",\n",
    "            \"checkpoint_ep{}_disc.pt\".format(train_config[\"start_epoch\"] - 1),\n",
    "        )\n",
    "        generator.load_state_dict(torch.load(gen_path, map_location=device))\n",
    "        discriminator.load_state_dict(torch.load(disc_path, map_location=device))\n",
    "\n",
    "    return device, data_loader, train_config, generator, discriminator, optimizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Loss\n",
    "\n",
    "The loss tells us how well the GAN is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6M04hCmDjdq"
   },
   "outputs": [],
   "source": [
    "def training_step_dcgan(\n",
    "    batch, device, generator, discriminator, optimizers, train_config, loss_fn\n",
    "):\n",
    "    \"\"\"Run the DCGAN training steps.\"\"\"\n",
    "    imgs = batch.to(device)\n",
    "\n",
    "    # Sample noise as generator input\n",
    "    z = torch.randn(imgs.size()[0], train_config[\"latent_dim\"], 1, 1).to(device)\n",
    "\n",
    "    valid = torch.ones(imgs.size(0)).to(device)\n",
    "    fake = torch.zeros(imgs.size(0)).to(device)\n",
    "\n",
    "    # -------------------\n",
    "    # Train Discriminator\n",
    "    # -------------------\n",
    "    optimizers[\"disc\"].zero_grad()\n",
    "    # Sample real\n",
    "    real_loss = loss_fn(discriminator(imgs), valid)\n",
    "    # Sample fake\n",
    "    gen_imgs = generator(z)  # generate fakes\n",
    "    fake_loss = loss_fn(discriminator(gen_imgs.detach()), fake)\n",
    "    # Backprop.\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    optimizers[\"disc\"].step()\n",
    "\n",
    "    # ---------------\n",
    "    # Train generator\n",
    "    # ---------------\n",
    "    optimizers[\"gen\"].zero_grad()\n",
    "    g_loss = loss_fn(discriminator(gen_imgs), valid)\n",
    "    # Backprop.\n",
    "    g_loss.backward()\n",
    "    optimizers[\"gen\"].step()\n",
    "\n",
    "    return g_loss, d_loss\n",
    "\n",
    "\n",
    "def run_training(args):\n",
    "    \"\"\"Initialize and run the full training process using the hyper-params in args.\"\"\"\n",
    "    (\n",
    "        device,\n",
    "        data_loader,\n",
    "        train_config,\n",
    "        generator,\n",
    "        discriminator,\n",
    "        optimizers,\n",
    "    ) = init_training(args)\n",
    "\n",
    "    # generate a sample with fixed seed, and reset the seed to pseudo-random\n",
    "    torch.manual_seed(42)\n",
    "    z_sample = torch.randn(\n",
    "        train_config[\"batch_size\"], train_config[\"latent_dim\"], 1, 1\n",
    "    ).to(device)\n",
    "    torch.manual_seed(random.randint(0, 1e10))\n",
    "\n",
    "    # Loss function for DCGAN\n",
    "    if args.gan_type == \"dcgan\":\n",
    "        loss_fn = torch.nn.BCELoss().to(device)\n",
    "\n",
    "    # Training\n",
    "    print(\"Training:\")\n",
    "    for epoch in range(train_config[\"start_epoch\"], train_config[\"max_epoch\"] + 1):\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            g_loss, d_loss = training_step_dcgan(\n",
    "                batch,\n",
    "                device,\n",
    "                generator,\n",
    "                discriminator,\n",
    "                optimizers,\n",
    "                train_config,\n",
    "                loss_fn,\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"\\nEpoch {}/{}:\\n\"\n",
    "            \"  Discriminator loss={:.4f}\\n\"\n",
    "            \"  Generator loss={:.4f}\".format(\n",
    "                epoch, train_config[\"max_epoch\"], d_loss.item(), g_loss.item()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch == 1 or epoch % train_config[\"sample_save_freq\"] == 0:\n",
    "            # Save sample\n",
    "            gen_sample = generator(z_sample)\n",
    "            save_image_grid(\n",
    "                img_batch=gen_sample[: train_config[\"grid_size\"] ** 2]\n",
    "                .detach()\n",
    "                .cpu()\n",
    "                .numpy(),\n",
    "                grid_size=train_config[\"grid_size\"],\n",
    "                epoch=epoch,\n",
    "                img_path=os.path.join(\n",
    "                    args.checkpoint_path,\n",
    "                    \"samples\",\n",
    "                    \"checkpoint_ep{}_sample.png\".format(epoch),\n",
    "                ),\n",
    "            )\n",
    "            print(\"Image sample saved.\")\n",
    "\n",
    "        if epoch == 1 or epoch % train_config[\"save_freq\"] == 0:\n",
    "            # Save checkpoint\n",
    "            gen_path = os.path.join(\n",
    "                args.checkpoint_path, \"weights\", \"checkpoint_ep{}_gen.pt\".format(epoch)\n",
    "            )\n",
    "            disc_path = os.path.join(\n",
    "                args.checkpoint_path, \"weights\", \"checkpoint_ep{}_disc.pt\".format(epoch)\n",
    "            )\n",
    "            torch.save(generator.state_dict(), gen_path)\n",
    "            torch.save(discriminator.state_dict(), disc_path)\n",
    "            print(\"Checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEfEYlYCDvEL"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show an image of our fake data while the GAN is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QblwpY0DDx-F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYgF4FEvD11n"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPQLMoXoEHHI"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LQBDqPzEkH5"
   },
   "outputs": [],
   "source": [
    "# Size input image for discriminator\n",
    "real_size = (128, 128, 3)\n",
    "\n",
    "# Size of latent vector to generator\n",
    "z_dim = 100\n",
    "learning_rate_D = 0.000005  # Thanks to Alexia Jolicoeur Martineau https://ajolicoeur.wordpress.com/cats/\n",
    "learning_rate_G = 0.00002  # Thanks to Alexia Jolicoeur Martineau https://ajolicoeur.wordpress.com/cats/\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "alpha = 0.2\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2gbQewtEoWP"
   },
   "outputs": [],
   "source": [
    "# Load the data and train the network here\n",
    "dataset = Dataset(resized_data_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMkIdSOeEs3B",
    "outputId": "b696e715-e253-4e2b-c191-1ef2c66fa03a"
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xtqOrcWuEwC6",
    "outputId": "029c43f7-6d9a-441f-84ea-be0cfd4850db"
   },
   "outputs": [],
   "source": [
    "train_config = dict()\n",
    "train_config[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Generated Images\n",
    "\n",
    "- Give it a larger dataset (~10K images)\n",
    "- Run for a larger number of epochs\n",
    "\n",
    "## Learning More About GANs\n",
    "\n",
    "- Two books about GANs are on their way to the library. \n",
    "- If you find something interesting, maybe send it to me and I can ask for it to be ordered too.\n",
    "\n",
    "## Interesting ML / GANs Tools\n",
    "\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
